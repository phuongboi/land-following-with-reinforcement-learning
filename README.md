### This repository is my re-implement apart of the [master thesis](https://github.com/clamesc/Training-Neural-Networks-for-Event-Based-End-to-End-Robot-Control)
#### [09/10/2023] Training with Q-learning
* Using CoppeliaSim(V-REP), ROS, Q-learning
* Simple implementation with pytorch
* Modify the ROS interface with new V-REP version
* Run `python train_qnetwork.py`
##### Training result
![alt text](/home/samvdh/2023_RL/code/land-following-with-reinforement-learning/figures/recording_2023_10_19-06_46-39.gif)  


### Reference
* [1] https://github.com/clamesc/Training-Neural-Networks-for-Event-Based-End-to-End-Robot-Control
* [2] Mnih, Volodymyr, et al. "Playing atari with deep reinforcement learning." arXiv preprint arXiv:1312.5602 (2013).
