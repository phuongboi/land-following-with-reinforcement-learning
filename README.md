### This repository is my re-implementation some experiments of the Master's thesis [Training Neural Networks for Event-Based End-to-End Robot Control](https://github.com/clamesc/Training-Neural-Networks-for-Event-Based-End-to-End-Robot-Control)
#### [19/10/2023] Training with Q-learning
* Using CoppeliaSim(V-REP), ROS, Q-learning
* Simple and friendly implementation with pytorch
* Modify the ROS interface with new V-REP version
* Run `python train_qnetwork.py`
##### Training result
![alt text](https://github.com/phuongboi/land-following-with-reinforcement-learning/blob/main/figures/recording_2023_10_19-06_46-39.gif)  


### Reference
* [1] https://github.com/clamesc/Training-Neural-Networks-for-Event-Based-End-to-End-Robot-Control
* [2] Mnih, Volodymyr, et al. "Playing atari with deep reinforcement learning." arXiv preprint arXiv:1312.5602 (2013).
